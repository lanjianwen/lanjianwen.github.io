<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[BP神经网络]]></title>
    <url>%2F2019%2F09%2F28%2FBP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[前言由于传统的感知器和线性神经网络有自身无法克服的缺陷，它们都不能解决线性不可分问题，因此在实际应用过程中受到了限制。而BP网络却拥有良好的繁泛化能力、容错能力以及非线性映射能力。因此成为应用最为广泛的一种神经网络。 基于BP算法的多层前馈型网络模型的拓扑结构图 BP算法的基本思想学习过程 第一阶段:第一阶段是信号的正向传播过程；输入信息通过输入层、隐层逐层处理并计算每个单元的实际输出值举个例子:比如你有100万钱，分别投资三个公司。W为投资某个公司的钱占所有钱的百分比，V为每个公司的利润率,收益即为Y=100W1V1+100W2V2+100+W3*V3 第二阶段:第二阶段是误差的反向传递过程；若在输入层未能得到期望的输出值，则逐层递归的计算实际输出和期望输出的差值（即误差），以便根据此差值调节权值。这种过程不断迭代，最后使得信号误差达到允许或规定的范围之内举个例子:有一个游戏叫做”数字炸弹”，规则:一般十个人以上玩，主持人出数字，其他人猜。主持人写下在1-100之间随便1个数字，不能让猜得人知道。其他的人就可以开始猜。如：56。每个人开始猜猜数字，如：A说:30 主持人说：30到100 ，B在从30到100中猜数字说：60，主持人在说：30到60，………… Z说：56，游戏结束主持人反馈的信息就是反向传播代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132% BP网络% BP神经网络的构建net=newff([-1 2;0 5],[3,1],&#123;&apos;tansig&apos;,&apos;purelin&apos;&#125;,&apos;traingd&apos;)net.IW&#123;1&#125;net.b&#123;1&#125;p=[1;2];a=sim(net,p)net=init(net);net.IW&#123;1&#125;net.b&#123;1&#125;a=sim(net,p)%net.IW&#123;1&#125;*p+net.b&#123;1&#125;p2=net.IW&#123;1&#125;*p+net.b&#123;1&#125;a2=sign(p2)a3=tansig(a2)a4=purelin(a3)net.b&#123;2&#125;net.b&#123;1&#125;net.IW&#123;1&#125;net.IW&#123;2&#125;0.7616+net.b&#123;2&#125;a-net.b&#123;2&#125;(a-net.b&#123;2&#125;)/ 0.7616help purelinp1=[0;0];a5=sim(net,p1)net.b&#123;2&#125;% BP网络% BP神经网络的构建net=newff([-1 2;0 5],[3,1],&#123;&apos;tansig&apos;,&apos;purelin&apos;&#125;,&apos;traingd&apos;)net.IW&#123;1&#125;net.b&#123;1&#125;%p=[1;];p=[1;2];a=sim(net,p)net=init(net);net.IW&#123;1&#125;net.b&#123;1&#125;a=sim(net,p)net.IW&#123;1&#125;*p+net.b&#123;1&#125;p2=net.IW&#123;1&#125;*p+net.b&#123;1&#125;a2=sign(p2)a3=tansig(a2)a4=purelin(a3)net.b&#123;2&#125;net.b&#123;1&#125;P=[1.2;3;0.5;1.6]W=[0.3 0.6 0.1 0.8]net1=newp([0 2;0 2;0 2;0 2],1,&apos;purelin&apos;);net2=newp([0 2;0 2;0 2;0 2],1,&apos;logsig&apos;);net3=newp([0 2;0 2;0 2;0 2],1,&apos;tansig&apos;);net4=newp([0 2;0 2;0 2;0 2],1,&apos;hardlim&apos;);net1.IW&#123;1&#125;net2.IW&#123;1&#125;net3.IW&#123;1&#125;net4.IW&#123;1&#125;net1.b&#123;1&#125;net2.b&#123;1&#125;net3.b&#123;1&#125;net4.b&#123;1&#125;net1.IW&#123;1&#125;=W;net2.IW&#123;1&#125;=W;net3.IW&#123;1&#125;=W;net4.IW&#123;1&#125;=W;a1=sim(net1,P)a2=sim(net2,P)a3=sim(net3,P)a4=sim(net4,P)init(net1);net1.b&#123;1&#125;help tansig% 训练p=[-0.1 0.5]t=[-0.3 0.4]w_range=-2:0.4:2;b_range=-2:0.4:2;ES=errsurf(p,t,w_range,b_range,&apos;logsig&apos;);%单输入神经元的误差曲面plotes(w_range,b_range,ES)%绘制单输入神经元的误差曲面pause(0.5);hold off;net=newp([-2,2],1,&apos;logsig&apos;);net.trainparam.epochs=100;net.trainparam.goal=0.001;figure(2);[net,tr]=train(net,p,t);title(&apos;动态逼近&apos;)wight=net.iw&#123;1&#125;bias=net.bpause;close;% 练p=[-0.2 0.2 0.3 0.4]t=[-0.9 -0.2 1.2 2.0]h1=figure(1);net=newff([-2,2],[5,1],&#123;&apos;tansig&apos;,&apos;purelin&apos;&#125;,&apos;trainlm&apos;);net.trainparam.epochs=100;net.trainparam.goal=0.0001;net=train(net,p,t);a1=sim(net,p)pause;h2=figure(2);plot(p,t,&apos;*&apos;);title(&apos;样本&apos;)title(&apos;样本&apos;);xlabel(&apos;Input&apos;);ylabel(&apos;Output&apos;);pause;hold on;ptest1=[0.2 0.1]ptest2=[0.2 0.1 0.9]a1=sim(net,ptest1);a2=sim(net,ptest2);net.iw&#123;1&#125;net.iw&#123;2&#125;net.b&#123;1&#125;net.b&#123;2&#125; 结果截图]]></content>
      <categories>
        <category>计算智能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[github+hexo搭建博客]]></title>
    <url>%2F2019%2F09%2F20%2Fgithub-hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[利用Github+Hexo搭建个人博客 准备工作 申请github账号github官网 下载并安装 Node.js下载与安装教程 下载并安装 Git下载与安装教程 安装Hexo和本地部署博客4.1. 新建文件夹Hexo(以后代码都放这)4.2. 在 Hexo 目录下 鼠标右键选择Git Bash Here4.3. 输入命令npm install -g hexo-cli4.4. 查看是否安装成功，输入hexo -v 安装成功4.5. 输入hexo init回车-&gt;输入npm install之后会生成一些文件夹4.6. 输入hexo s-&gt;打开浏览器输入http://localhost:4000/即可看到本地博客部署 github搭建github博客 登陆自己的github账号 新建一个仓库 ：点击在右上角+-&gt;New repository-&gt;在Repository name 输入仓库名字 xxx.github.io以后仓库名就是你的博客地址。 配置SSH Key ：一般在你的C盘用户目录下-&gt;找到隐藏文件.ssh文件夹-&gt;有私钥id_rsa 公钥id_rsa.pub-&gt;复制公钥(如果没有.ssh文件夹，打开Git Bush输入 ssh-keygen -t rsa -C &quot;你的邮箱地址&quot;)在你的github选择settings进入到 在Git Bush输入ssh -T git@github.com查看是否配置成功 将本地博客部署到github 安装github插件依赖：在Hexo文件目录下打开Git Bash输入npm install hexo-deployer-git --save 修改站点文件(Hexo文件夹下_config.yml) 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:&lt;github账号名称&gt;/&lt;github账号名称&gt;.github.io.git branch: master 输入hexo g &amp;&amp; hexo d-&gt;在浏览器输入http://xxx.github.io即可看到本地博客部署到github上s]]></content>
  </entry>
  <entry>
    <title><![CDATA[K-Means]]></title>
    <url>%2F2019%2F09%2F17%2FK-Means%2F</url>
    <content type="text"><![CDATA[K-means算法介绍 从D中随机取k个元素，作为k个簇的各自的中心。 分别计算剩下的元素到k个簇中心的相异度，将这些元素分别划归到相异度最低的簇。 根据聚类结果，重新计算k个簇各自的中心，计算方法是取簇中所有元素各自维度的算术平均数。 将D中全部元素按照新的中心重新聚类。 重复第4步，直到聚类结果不再变化。 将结果输出。JAVA代码实现分装Point类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package Kmeans;public class Point &#123; private float[] localArray; private int id; private int clusterId; // 标识属于哪个类中心。 private float dist; // 标识和所属类中心的距离。 public Point(int id, float[] localArray) &#123; this.id = id; this.localArray = localArray; &#125; public Point(float[] localArray) &#123; this.id = -1; //表示不属于任意一个类 this.localArray = localArray; &#125; public float[] getlocalArray() &#123; return localArray; &#125; public int getId() &#123; return id; &#125; public void setClusterId(int clusterId) &#123; this.clusterId = clusterId; &#125; public int getClusterid() &#123; return clusterId; &#125; public float getDist() &#123; return dist; &#125; public void setDist(float dist) &#123; this.dist = dist; &#125; @Override public String toString() &#123; String result = "Point_id=" + id + " ["; for (int i = 0; i &lt; localArray.length; i++) &#123; result += localArray[i] + " "; &#125; return result.trim()+"] clusterId: "+clusterId+" dist: "+dist; &#125; @Override public boolean equals(Object obj) &#123; if (obj == null || getClass() != obj.getClass()) return false; Point point = (Point) obj; if (point.localArray.length != localArray.length) return false; for (int i = 0; i &lt; localArray.length; i++) &#123; if (Float.compare(point.localArray[i], localArray[i]) != 0) &#123; return false; &#125; &#125; return true; &#125; @Override public int hashCode() &#123; float x = localArray[0]; float y = localArray[localArray.length - 1]; long temp = x != +0.0d ? Double.doubleToLongBits(x) : 0L; int result = (int) (temp ^ (temp &gt;&gt;&gt; 32)); temp = y != +0.0d ? Double.doubleToLongBits(y) : 0L; result = 31 * result + (int) (temp ^ (temp &gt;&gt;&gt; 32)); return result; &#125;&#125; 封装Cluster123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package Kmeans;import java.util.ArrayList;import java.util.List; public class Cluster &#123; private int id;// 标识 private Point center;// 中心 private List&lt;Point&gt; members = new ArrayList&lt;Point&gt;();// 成员 public Cluster(int id, Point center) &#123; this.id = id; this.center = center; &#125; public Cluster(int id, Point center, List&lt;Point&gt; members) &#123; this.id = id; this.center = center; this.members = members; &#125; public void addPoint(Point newPoint) &#123; if (!members.contains(newPoint))&#123; members.add(newPoint); &#125;else&#123; System.out.println("样本数据点 &#123;"+newPoint.toString()+"&#125; 已经存在！"); &#125; &#125; public int getId() &#123; return id; &#125; public Point getCenter() &#123; return center; &#125; public void setCenter(Point center) &#123; this.center = center; &#125; public List&lt;Point&gt; getMembers() &#123; return members; &#125; @Override public String toString() &#123; String toString = "Cluster \n" + "Cluster_id=" + this.id + ", center:&#123;" + this.center.toString()+"&#125;"; for (Point point : members) &#123; toString+="\n"+point.toString(); &#125; return toString+"\n"; &#125;&#125; 求两个点的欧式距离12345678910111213141516171819202122package Kmeans;public class DistanceCompute &#123; /** * 求欧式距离 */ public double getEuclideanDis(Point p1, Point p2) &#123; double count_dis = 0; float[] p1_local_array = p1.getlocalArray(); float[] p2_local_array = p2.getlocalArray(); if (p1_local_array.length != p2_local_array.length) &#123; throw new IllegalArgumentException("length of array must be equal!"); &#125; for (int i = 0; i &lt; p1_local_array.length; i++) &#123; count_dis += Math.pow(p1_local_array[i] - p2_local_array[i], 2); &#125; return Math.sqrt(count_dis); &#125;&#125; 核心运行类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154package Kmeans;import java.util.ArrayList;import java.util.HashSet;import java.util.List;import java.util.Random;import java.util.Set; public class KMeansRun &#123; private int kNum; //簇的个数 private int iterNum = 10; //迭代次数 private int iterMaxTimes = 100000; //单次迭代最大运行次数 private int iterRunTimes = 0; //单次迭代实际运行次数 private float disDiff = (float) 0.01; //单次迭代终止条件，两次运行中类中心的距离差 private List&lt;float[]&gt; original_data =null; //用于存放，原始数据集 private static List&lt;Point&gt; pointList = null; //用于存放，原始数据集所构建的点集 private DistanceCompute disC = new DistanceCompute(); private int len = 0; //用于记录每个数据点的维度 public KMeansRun(int k, List&lt;float[]&gt; original_data) &#123; this.kNum = k; this.original_data = original_data; this.len = original_data.get(0).length; //检查规范 check(); //初始化点集。 init(); &#125; /** * 检查规范 */ private void check() &#123; if (kNum == 0)&#123; throw new IllegalArgumentException("k must be the number &gt; 0"); &#125; if (original_data == null)&#123; throw new IllegalArgumentException("program can't get real data"); &#125; &#125; /** * 初始化数据集，把数组转化为Point类型。 */ private void init() &#123; pointList = new ArrayList&lt;Point&gt;(); for (int i = 0, j = original_data.size(); i &lt; j; i++)&#123; pointList.add(new Point(i, original_data.get(i))); &#125; &#125; /** * 随机选取中心点，构建成中心类。 */ private Set&lt;Cluster&gt; chooseCenterCluster() &#123; Set&lt;Cluster&gt; clusterSet = new HashSet&lt;Cluster&gt;(); Random random = new Random(); for (int id = 0; id &lt; kNum; ) &#123; Point point = pointList.get(random.nextInt(pointList.size())); // 用于标记是否已经选择过该数据。 boolean flag =true; for (Cluster cluster : clusterSet) &#123; if (cluster.getCenter().equals(point)) &#123; flag = false; &#125; &#125; // 如果随机选取的点没有被选中过，则生成一个cluster if (flag) &#123; Cluster cluster =new Cluster(id, point); clusterSet.add(cluster); id++; &#125; &#125; return clusterSet; &#125; /** * 为每个点分配一个类！ */ public void cluster(Set&lt;Cluster&gt; clusterSet)&#123; // 计算每个点到K个中心的距离，并且为每个点标记类别号 for (Point point : pointList) &#123; float min_dis = Integer.MAX_VALUE; for (Cluster cluster : clusterSet) &#123; float tmp_dis = (float) Math.min(disC.getEuclideanDis(point, cluster.getCenter()), min_dis); if (tmp_dis != min_dis) &#123; min_dis = tmp_dis; point.setClusterId(cluster.getId()); point.setDist(min_dis); &#125; &#125; &#125; // 新清除原来所有的类中成员。把所有的点，分别加入每个类别 for (Cluster cluster : clusterSet) &#123; cluster.getMembers().clear(); for (Point point : pointList) &#123; if (point.getClusterid()==cluster.getId()) &#123; cluster.addPoint(point); &#125; &#125; &#125; &#125; /** * 计算每个类的中心位置！ */ public boolean calculateCenter(Set&lt;Cluster&gt; clusterSet) &#123; boolean ifNeedIter = false; for (Cluster cluster : clusterSet) &#123; List&lt;Point&gt; point_list = cluster.getMembers(); float[] sumAll =new float[len]; // 所有点，对应各个维度进行求和 for (int i = 0; i &lt; len; i++) &#123; for (int j = 0; j &lt; point_list.size(); j++) &#123; sumAll[i] += point_list.get(j).getlocalArray()[i]; &#125; &#125; // 计算平均值 for (int i = 0; i &lt; sumAll.length; i++) &#123; sumAll[i] = (float) sumAll[i]/point_list.size(); &#125; // 计算两个新、旧中心的距离，如果任意一个类中心移动的距离大于dis_diff则继续迭代。 if(disC.getEuclideanDis(cluster.getCenter(), new Point(sumAll)) &gt; disDiff)&#123; ifNeedIter = true; &#125; // 设置新的类中心位置 cluster.setCenter(new Point(sumAll)); &#125; return ifNeedIter; &#125; /** * 运行 k-means */ public Set&lt;Cluster&gt; run() &#123; Set&lt;Cluster&gt; clusterSet= chooseCenterCluster(); boolean ifNeedIter = true; while (ifNeedIter) &#123; cluster(clusterSet); ifNeedIter = calculateCenter(clusterSet); iterRunTimes ++ ; &#125; return clusterSet; &#125; /** * 返回实际运行次数 */ public int getIterTimes() &#123; return iterRunTimes; &#125;&#125; 测试类123456789101112131415161718192021222324252627282930313233package Kmeans;import java.util.ArrayList;import java.util.Set; public class Main &#123; public static void main(String[] args) &#123; ArrayList&lt;float[]&gt; dataSet = new ArrayList&lt;float[]&gt;(); dataSet.add(new float[] &#123; 1, 2, 3 &#125;); dataSet.add(new float[] &#123; 3, 3, 3 &#125;); dataSet.add(new float[] &#123; 3, 4, 4&#125;); dataSet.add(new float[] &#123; 5, 6, 5&#125;); dataSet.add(new float[] &#123; 8, 9, 6&#125;); dataSet.add(new float[] &#123; 4, 5, 4&#125;); dataSet.add(new float[] &#123; 6, 4, 2&#125;); dataSet.add(new float[] &#123; 3, 9, 7&#125;); dataSet.add(new float[] &#123; 5, 9, 8&#125;); dataSet.add(new float[] &#123; 4, 2, 10&#125;); dataSet.add(new float[] &#123; 1, 9, 12&#125;); dataSet.add(new float[] &#123; 7, 8, 112&#125;); dataSet.add(new float[] &#123; 7, 8, 4&#125;); KMeansRun kRun =new KMeansRun(3, dataSet); Set&lt;Cluster&gt; clusterSet = kRun.run(); System.out.println("单次迭代运行次数："+kRun.getIterTimes()); for (Cluster cluster : clusterSet) &#123; System.out.println(cluster); &#125; &#125;&#125; 结果截图]]></content>
      <categories>
        <category>计算智能</category>
      </categories>
  </entry>
</search>
