<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SIFT特征提取与检索]]></title>
    <url>%2F2020%2F03%2F08%2FSIFT%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B8%8E%E6%A3%80%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[SIFT特征提取与检索 SIFT概述SIFT算法描述SIFT特征不只具有尺度不变性，即使改变旋转角度，图像亮度或拍摄视角，仍然能够得到好的检测效果。 SIFT算法具的特点1.图像的局部特征，对旋转、尺度缩放、亮度变化保持不变，对视角变化、仿射变换、噪声也保持一定程度的稳定性。2.独特性好，信息量丰富，适用于海量特征库进行快速、准确的匹配。3.多量性，即使是很少几个物体也可以产生大量的SIFT特征4.高速性，经优化的SIFT匹配算法甚至可以达到实时性5.扩招性，可以很方便的与其他的特征向量进行联合。 SIFT特征检测的步骤1.尺度空间的极值检测 搜索所有尺度空间上的图像，通过高斯微分函数来识别潜在的对尺度和选择不变的兴趣点。2.特征点定位 在每个候选的位置上，通过一个拟合精细模型来确定位置尺度，关键点的选取依据他们的稳定程度。3.特征方向赋值 基于图像局部的梯度方向，分配给每个关键点位置一个或多个方向，后续的所有操作都是对于关键点的方向、尺度和位置进行变换，从而提供这些特征的不变性。4.特征点描述 在每个特征点周围的邻域内，在选定的尺度上测量图像的局部梯度，这些梯度被变换成一种表示，这种表示允许比较大的局部形状的变形和光照变换。 尺度空间在一定的范围内，无论物体是大还是小，人眼都可以分辨出来。然而计算机要有相同的能力却不是那么的容易，在未知的场景中，计算机视觉并不能提供物体的尺度大小，其中的一种方法是把物体不同尺度下的图像都提供给机器，让机器能够对物体在不同的尺度下有一个统一的认知。在建立统一认知的过程中，要考虑的就是在图像在不同的尺度下都存在的特征点。 多分辨率图像金字塔在早期图像的多尺度通常使用图像金字塔表示形式。图像金字塔是同一图像在不同的分辨率下得到的一组结果，其生成过程一般包括两个步骤： 对原始图像进行平滑对处理后的图像进行降采样（通常是水平、垂直方向的1/2）降采样后得到一系列不断尺寸缩小的图像。显然，一个传统的金字塔中，每一层的图像是其上一层图像长、高的各一半。多分辨率的图像金字塔虽然生成简单，但其本质是降采样，图像的局部特征则难以保持，也就是无法保持特征的尺度不变性。 高斯尺度空间我们还可以通过图像的模糊程度来模拟人在距离物体由远到近时物体在视网膜上成像过程，距离物体越近其尺寸越大图像也越模糊，这就是高斯尺度空间，使用不同的参数模糊图像（分辨率不变），是尺度空间的另一种表现形式。我们知道图像和高斯函数进行卷积运算能够对图像进行模糊，使用不同的“高斯核”可得到不同模糊程度的图像。一副图像其高斯尺度空间可由其和不同的高斯卷积得到：L(x,y,σ)=G(x,y,σ)∗I(x,y) 其中，G(x,y,σ)是高斯核函数。G(x,y,σ)=12πσ2ex2+y22σ2 σ称为尺度空间因子，它是高斯正态分布的标准差，反映了图像被模糊的程度，其值越大图像越模糊，对应的尺度也就越大。L(x,y,σ)代表着图像的高斯尺度空间。构建尺度空间的目的是为了检测出在不同的尺度下都存在的特征点，而检测特征点较好的算子是Δ2G(高斯拉普拉斯,LoG）,Δ2=∂2∂x2+∂2∂y2 使用LoG虽然能较好的检测到图像中的特征点，但是其运算量过大，通常可使用DoG（差分高斯，Difference of Gaussina）来近似计算LoG[Marr and Hidreth]。设k为相邻两个高斯尺度空间的比例因子，则DoG的定义：D(x,y,σ)=[G(x,y,kσ)−G(x,y,σ)]∗I(x,y)=L(x,y,kσ)−L(x,y,σ) 其中，L(x,y,σ)是图像的高斯尺度空间。从上式可以知道，将相邻的两个高斯空间的图像相减就得到了DoG的响应图像。为了得到DoG图像，先要构建高斯尺度空间，而高斯的尺度空间可以在图像金字塔降采样的基础上加上高斯滤波得到，也就是对图像金字塔的每层图像使用不同的参数σ进行高斯模糊，使每层金字塔有多张高斯模糊过的图像。降采样时，金字塔上边一组图像的第一张是由其下面一组图像倒数第三张降采样得到。易知，高斯金字塔有多组，每组又有多层。一组中的多个层之间的尺度是不一样的（也就是使用的高斯参数σ是不同的），相邻两层之间的尺度相差一个比例因子k。如果每组有S层，则k=21S。上一组图像的最底层图像是由下一组中尺度为2σ的图像进行因子为2的降采样得到的（高斯金字塔先从底层建立）。高斯金字塔构建完成后，将相邻的高斯金字塔相减就得到了DoG金字塔。高斯金字塔的组数一般是o=[log2min(m,n)]−a o表示高斯金字塔的层数，m，n分别是图像的行和列。减去的系数a可以在0−log2min(m,n)之间的任意值，和具体需要的金字塔的顶层图像的大小有关。高斯模糊参数σ（尺度空间），可由下面关系式得到σ(o,s)=σ0⋅2o+sS 其中o为所在的组，s为所在的层，σ0为初始的尺度，S为每组的层数。在Lowe的算法实现中σ0=1.6,omin=−1,S=3，omin=−1就是首先将原图像的长和宽各扩展一倍。从上面可以得知同一组内相邻层的图像尺度关系σs+1=k⋅σs=21S⋅σs 相邻组之间的尺度关系σo+1=2σo 高斯金字塔构建示例以一个512×512的图像I为例，构建高斯金字塔步骤：(从0开始计数，倒立的金字塔）金字塔的组数，log2512=9，减去因子3，构建的金字塔的组数为6。取每组的层数为3。构建第0组，将图像的宽和高都增加一倍，变成1024×1024（I0）。第0层I0∗G(x,y,σ0)，第1层I0∗G(x,y,kσ0)，第2层I0∗G(x,y,k2σ0)构建第1组，对I0降采样变成512×512（I1）。第0层I1∗G(x,y,2σ0)，第1层I1∗G(x,y,2kσ0)I1∗G(x,y,2k2σ0) DoG空间极值检测为了寻找尺度空间的极值点，每个像素点要和其图像域（同一尺度空间）和尺度域（相邻的尺度空间）的所有相邻点进行比较，当其大于（或者小于）所有相邻点时，改点就是极值点。如图所示，中间的检测点要和其所在图像的3×3邻域8个像素点，以及其相邻的上下两层的3×3领域18个像素点，共26个像素点进行比较。从上面的描述中可以知道，每组图像的第一层和最后一层是无法进行比较取得极值的。为了满足尺度变换的连续性，在每一组图像的顶层继续使用高斯模糊生成3幅图像，高斯金字塔每组有S+3层图像，DoG金字塔的每组有S+2组图像。 求取特征点的主方向经过上面的步骤已经找到了在不同尺度下都存在的特征点，为了实现图像旋转不变性，需要给特征点的方向进行赋值。利用特征点邻域像素的梯度分布特性来确定其方向参数，再利用图像的梯度直方图求取关键点局部结构的稳定方向。找到了特征点，也就可以得到该特征点的尺度σ，也就可以得到特征点所在的尺度图像L(x,y)=G(x,y,σ)∗I(x,y) 计算以特征点为中心、以3×1.5σ为半径的区域图像的幅角和幅值，每个点L(x,y)的梯度的模m(x,y)以及方向θ(x,y)可通过下面公司求得 计算得到梯度方向后，就要使用直方图统计特征点邻域内像素对应的梯度方向和幅值。梯度方向的直方图的横轴是梯度方向的角度（梯度方向的范围是0到360度，直方图每36度一个柱共10个柱，或者没45度一个柱共8个柱），纵轴是梯度方向对应梯度幅值的累加，在直方图的峰值就是特征点的主方向。在Lowe的论文还提到了使用高斯函数对直方图进行平滑以增强特征点近的邻域点对关键点方向的作用，并减少突变的影响。为了得到更精确的方向，通常还可以对离散的梯度直方图进行插值拟合。具体而言，关键点的方向可以由和主峰值最近的三个柱值通过抛物线插值得到。在梯度直方图中，当存在一个相当于主峰值80%能量的柱值时，则可以将这个方向认为是该特征点辅助方向。所以，一个特征点可能检测到多个方向（也可以理解为，一个特征点可能产生多个坐标、尺度相同，但是方向不同的特征点） 生成特征描述通过以上的步骤已经找到了SIFT特征点位置、尺度和方向信息，下面就需要使用一组向量来描述关键点也就是生成特征点描述子，这个描述符不只包含特征点，也含有特征点周围对其有贡献的像素点特征描述符的生成大致有三个步骤：1.校正旋转主方向，确保旋转不变性。2.生成描述子，最终形成一个128维的特征向量3.归一化处理，将特征向量长度进行归一化处理，进一步去除光照的影响 数据集 SIFT特征提取并展示特征点代码 12345678910111213141516171819202122232425262728293031323334from PIL import Imagefrom pylab import *from PCV.localdescriptors import siftfrom PCV.localdescriptors import harris# 添加中文字体支持from matplotlib.font_manager import FontPropertiesfont = FontProperties(fname=r&quot;c:\windows\fonts\SimSun.ttc&quot;, size=14)imname = &apos;D:/Hexo/source/_posts/SIFT特征提取与检索/1-1.png&apos;im = array(Image.open(imname).convert(&apos;L&apos;))sift.process_image(imname, &apos;empire.sift&apos;)l1, d1 = sift.read_features_from_file(&apos;empire.sift&apos;)figure()gray()subplot(131)sift.plot_features(im, l1, circle=False)title(u&apos;SIFT特征&apos;,fontproperties=font)subplot(132)sift.plot_features(im, l1, circle=True)title(u&apos;用圆圈表示SIFT特征尺度&apos;,fontproperties=font)# 检测harris角点harrisim = harris.compute_harris_response(im)subplot(133)filtered_coords = harris.get_harris_points(harrisim, 6, 0.1)imshow(im)plot([p[1] for p in filtered_coords], [p[0] for p in filtered_coords], &apos;*&apos;)axis(&apos;off&apos;)title(u&apos;Harris角点&apos;,fontproperties=font)show() 小结：相比Harris，SIFT能检测出更丰富点 给定两张图片，计算其SIFT特征匹配结果第一组第二组小结：由于旋转不变性和尺度不变性，即使两张不完全一样图，只有存在相同特征点就会特征匹配 给定一张输入的图片，在数据集内部进行检索，输出与其匹配最多的三张图片原图匹配最多的三张图 总结1.实验中碰到的困难在进行SIFT特征匹配实验时，要求两张图片的维度一致，我直接将之转化为灰度图像。2.SIFT缺点(1)实时性不高(2)有时候特征点特别少(3)对边缘光滑的目标无法准确提取特征点]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Harris角点检测]]></title>
    <url>%2F2020%2F02%2F25%2FHarris%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[Harris角点检测原理详解 基本原理人眼对角点的识别通常是在一个局部的小区域或小窗口完成的。如果在各个方向上移动这个特征的小窗口，窗口内区域的灰度发生了较大的变化，那么就认为在窗口内遇到了角点。如果这个特定的窗口在图像各个方向上移动时，窗口内图像的灰度没有发生变化，那么窗口内就不存在角点；如果窗口在某一个方向移动时，窗口内图像的灰度发生了较大的变化，而在另一些方向上没有发生变化，那么，窗口内的图像可能就是一条直线的线段。 算法思想算法基本思想是使用一个固定窗口在图像上进行任意方向上的滑动，比较滑动前与滑动后两种情况，窗口中的像素灰度变化程度，如果存在任意方向上的滑动，都有着较大灰度变化，那么我们可以认为该窗口中存在角点。 从图像局部的小窗口观察图像特征 角点定义  窗口向任意方向的移动都导致图像灰度的明 显变化数学表达式 算法实现可以将Harris图像角点检测算法归纳如下，共分以下五步： 计算图像I(x,y)在X和Y两个方向的梯度Ix、Iy。 Ix=∂I∂x=I⊗(−1 0 1)，Iy=∂I∂x=I⊗(−1 0 1)T 计算图像两个方向梯度的乘积。 I2x=Ix⋅Iy，I2y=Iy⋅Iy，Ixy=Ix⋅Iy 使用高斯函数对I2x、I2y和Ixy进行高斯加权（取σ=1），生成矩阵M的元素A、B和C。 A=g(I2x)=I2x⊗w，C=g(I2y)=I2y⊗w，B=g(Ix,y)=Ixy⊗w 计算每个像素的Harris响应值R，并对小于某一阈值t的R置为零。 R={R:detM−α(traceM)2&lt;t} 在3×3或5×5的邻域内进行非最大值抑制，局部最大值点即为图像中的角点。 代码实现1234567891011121314151617181920212223242526272829303132333435# -*- coding: utf-8 -*-from pylab import *from PIL import Imagefrom PCV.localdescriptors import harris# 读入图像im = array(Image.open(r&apos;E:\学习\计算机视觉\images\3-4.jpg&apos;).convert(&apos;L&apos;))imshow(Image.open(r&apos;E:\学习\计算机视觉\images\3-4.jpg&apos;))# 检测harris角点harrisim = harris.compute_harris_response(im)# Harris响应函数harrisim1 = 255 - harrisimfigure()gray()#画出Harris响应图subplot(141)imshow(harrisim1)print (harrisim1.shape)axis(&apos;off&apos;)axis(&apos;equal&apos;)threshold = [0.01, 0.05, 0.1]for i, thres in enumerate(threshold): filtered_coords = harris.get_harris_points(harrisim, 6, thres) subplot(1, 4, i+2) imshow(im) print (im.shape) plot([p[1] for p in filtered_coords], [p[0] for p in filtered_coords], &apos;*&apos;) axis(&apos;off&apos;)show() 实验结果场景一：角点丰富 原图(近距离) 亮度暗 侧面 旋转 远距离 `结果分析:由角点丰富的图片实验可得 亮度变化，角点数量会发生变化。 正面，侧面，旋转角点特征位置不发生变化 距离改变，角点特征位置，数量改变` 场景二：边缘丰富 原图(近距离) 亮度暗 侧面 旋转 远距离 `结果分析:由边缘丰富的图片实验可得 亮度变化，角点数量会发生变化。 正面，侧面，旋转角点特征位置不发生变化 距离改变，角点特征位置，数量改变` 场景三：纹理平坦 原图(近距离) 亮度暗 侧面 旋转 远距离 结果分析: 由角点丰富的图片实验可得 1.亮度变化，角点数量会发生变化。 2.正面，侧面，旋转角点特征位置不发生变化 3.距离改变，角点特征位置，数量改变 实验总结` Harris角点检测算子对亮度的变化不敏感这是因为在进行Harris角点检测时，使用了微分算子对图像进行微分运算，而微分运算对图像密度的拉升或收缩和对亮度的抬高或下降不敏感。换言之，对亮度和对比度的仿射变换并不改变Harris响应的极值点出现的位置，但是，由于阈值的选择，可能会影响角点检测的数量 Harris角点检测算子具有旋转不变性Harris角点检测算子使用的是角点附近的区域灰度二阶矩矩阵。而二阶矩矩阵可以表示成一个椭圆，椭圆的长短轴正是二阶矩矩阵特征值平方根的倒数。当特征椭圆转动时，特征值并不发生变化，所以判断角点响应值R也不发生变化，由此说明Harris角点检测算子具有旋转不变性 Harris角点检测算子不具有尺度不变性当尺寸被缩小时，在检测窗口尺寸不变的前提下，在窗口内所包含图像的内容是完全不同的。`]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Anaconda+Opencv安装]]></title>
    <url>%2F2020%2F02%2F20%2FAnaconda-Opencv%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[win10环境下安装Anaconda和Opencv Anaconda下载 官网下载 清华镜像源我这里下载的版本是Anaconda3-4.1.1-Windows-x86_64 对应 python3.5Anaconda安装 默认所有用户(这里影响不大) 选择自定义路径 默认就行 检查是否安装完成 Opencv下载安装 下载地址 选择版本，我这里选择opencv_python-4.1.2+contrib-cp35-cp35m-win_amd64.whl。 cp35就是python3.5 打开opencv所在目录，cmd 进入目录，执行1pip install opencv_python-4.1.2+contrib-cp35-cp35m-win_amd64.whl 如果报错，可能网络原因，再次执行，直到成功 测试是否安装成功 更新一下numpy 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade numpy 打开Spyder,执行代码 12345import cv2 img = cv2.imread(&quot;D:\2.png&quot;, 1)cv2.imshow(&quot;1&quot;, img)cv2.waitKey() 成功显示图片，安装成功]]></content>
      <categories>
        <category>python学习</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[图像处理基础]]></title>
    <url>%2F2020%2F02%2F20%2F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[python+opencv图像处理基础 PIL (Python Imaging Library)图像库提供了很多常用的图像处理及很多有用的图像基本操作。1.读入一幅图片，输出原图和灰度图的例子 代码 12345678910111213141516171819202122from PIL import Imagefrom pylab import *# 添加中文字体支持from matplotlib.font_manager import FontPropertiesfont = FontProperties(fname=r&quot;c:\windows\fonts\SimSun.ttc&quot;, size=14)figure()pil_im = Image.open(r&apos;C:\Users\LJW\Desktop\dog.jpg&apos;)gray()subplot(121)title(u&apos;原图&apos;,fontproperties=font)axis(&apos;off&apos;)imshow(pil_im)pil_im = Image.open(r&apos;C:\Users\LJW\Desktop\dog.jpg&apos;).convert(&apos;L&apos;)subplot(122)title(u&apos;灰度图&apos;,fontproperties=font)axis(&apos;off&apos;)imshow(pil_im)show() 结果截图 创建缩略图利用PIL可以很容易的创建缩略图，设置缩略图的大小，并用元组保存起来，调用thumnail()方法即可生成缩略图。 拷贝并粘贴区域调用crop()方法即可从一幅图像中进行区域拷贝，拷贝出区域后，可以对区域进行旋转等变换。 调整尺寸及旋转要对一幅图像的尺寸进行调整，可以调用resize()方法，元组中放置的便是你要调整尺寸的大小。如果要对图像进行旋转变换的话，可以调用rotate()方法代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# -*- coding: utf-8 -*-from PIL import Imagefrom pylab import *# 添加中文字体支持from matplotlib.font_manager import FontPropertiesfont = FontProperties(fname=r&quot;c:\windows\fonts\SimSun.ttc&quot;, size=14)figure()# 显示原图pil_im = Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;)print (pil_im.mode, pil_im.size, pil_im.format)subplot(231)title(u&apos;原图&apos;, fontproperties=font)axis(&apos;off&apos;)imshow(pil_im)# 显示灰度图pil_im = Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;).convert(&apos;L&apos;)gray()subplot(232)title(u&apos;灰度图&apos;, fontproperties=font)axis(&apos;off&apos;)imshow(pil_im)#拷贝粘贴区域pil_im = Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;)box = (100,100,400,400)region = pil_im.crop(box)region = region.transpose(Image.ROTATE_180)pil_im.paste(region,box)subplot(233)title(u&apos;拷贝粘贴区域&apos;, fontproperties=font)axis(&apos;off&apos;)imshow(pil_im)# 缩略图pil_im = Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;)size = 128, 128pil_im.thumbnail(size)print (pil_im.size)subplot(234)title(u&apos;缩略图&apos;, fontproperties=font)axis(&apos;off&apos;)imshow(pil_im)pil_im.save(&apos;C:/Users/LJW/Desktop/dog2.jpg&apos;) #保存缩略图# 调整图像尺寸pil_im = Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;)pil_im = pil_im.resize(size)print (pil_im.size)subplot(235)title(u&apos;调整尺寸后的图像&apos;, fontproperties=font)axis(&apos;off&apos;)imshow(pil_im)# 旋转图像45°pil_im = Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;)pil_im = pil_im.rotate(45)subplot(236)title(u&apos;旋转45°后的图像&apos;, fontproperties=font)axis(&apos;off&apos;)imshow(pil_im)show() 结果截图 图像轮廓和直方图图像轮廓线和图线等高线。在画图像轮廓前需要转换为灰度图像，因为轮廓需要获取每个坐标[x,y]位置的像素值代码 123456789101112131415161718192021222324# -*- coding: utf-8 -*-from PIL import Imagefrom pylab import *# 添加中文字体支持from matplotlib.font_manager import FontPropertiesfont = FontProperties(fname=r&quot;c:\windows\fonts\SimSun.ttc&quot;, size=14)im = array(Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;).convert(&apos;L&apos;)) # 打开图像，并转成灰度图像figure()subplot(121)gray()contour(im, origin=&apos;image&apos;)axis(&apos;equal&apos;)axis(&apos;off&apos;)title(u&apos;图像轮廓&apos;, fontproperties=font)subplot(122)hist(im.flatten(), 128)title(u&apos;图像直方图&apos;, fontproperties=font)plt.xlim([0,260])plt.ylim([0,11000])show() 结果截图 灰度变换在读入图像到NumPy数组后，就可以对它进行任何我们想要的操作了。对图像进行灰度变换便是一个简单的例子。代码 123456789101112131415161718192021222324252627282930313233from PIL import Imagefrom numpy import *from pylab import *im = array(Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;).convert(&apos;L&apos;))print (int(im.min()), int(im.max()))im2 = 255 - im # invert imageprint (int(im2.min()), int(im2.max()))im3 = (100.0/255) * im + 100 # clamp to interval 100...200print (int(im3.min()), int(im3.max()))im4 = 255.0 * (im/255.0)**2 # squaredprint (int(im4.min()), int(im4.max()))figure()gray()subplot(1, 3, 1)imshow(im2)axis(&apos;off&apos;)title(r&apos;$f(x)=255-x$&apos;)subplot(1, 3, 2)imshow(im3)axis(&apos;off&apos;)title(r&apos;$f(x)=\frac&#123;100&#125;&#123;255&#125;x+100$&apos;)subplot(1, 3, 3)imshow(im4)axis(&apos;off&apos;)title(r&apos;$f(x)=255(\frac&#123;x&#125;&#123;255&#125;)^2$&apos;)show() 结果截图：上面左边灰度变换函数采用的是f(x)=255-x,中间采用的是f(x)=(100/255)x+100,右边采用的是变换函数是f(x)=255(x/255)^2 直方图均衡化一个极其有用的例子是灰度变换后进行直方图均衡化。图像均衡化作为预处理操作，在归一化图像强度时是一个很好的方式，并且通过直方图均衡化可以增加图像对比度。代码 1234567891011121314151617181920212223242526272829303132333435363738# -*- coding: utf-8 -*-from PIL import Imagefrom pylab import *from PCV.tools import imtools# 添加中文字体支持from matplotlib.font_manager import FontPropertiesfont = FontProperties(fname=r&quot;c:\windows\fonts\SimSun.ttc&quot;, size=14)im = array(Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;).convert(&apos;L&apos;)) # 打开图像，并转成灰度图像#im = array(Image.open(&apos;../data/AquaTermi_lowcontrast.JPG&apos;).convert(&apos;L&apos;))im2, cdf = imtools.histeq(im)figure()subplot(2, 2, 1)axis(&apos;off&apos;)gray()title(u&apos;原始图像&apos;, fontproperties=font)imshow(im)subplot(2, 2, 2)axis(&apos;off&apos;)title(u&apos;直方图均衡化后的图像&apos;, fontproperties=font)imshow(im2)subplot(2, 2, 3)axis(&apos;off&apos;)title(u&apos;原始直方图&apos;, fontproperties=font)#hist(im.flatten(), 128, cumulative=True, normed=True)hist(im.flatten(), 128, normed=True)subplot(2, 2, 4)axis(&apos;off&apos;)title(u&apos;均衡化后的直方图&apos;, fontproperties=font)#hist(im2.flatten(), 128, cumulative=True, normed=True)hist(im2.flatten(), 128, normed=True)show() 结果截图 图像模糊一个经典的并且十分有用的图像卷积例子是对图像进行高斯模糊。高斯模糊可以用于定义图像尺度、计算兴趣点以及很多其他的应用场合。代码 1234567891011121314151617181920212223242526272829303132333435363738394041 # -*- coding: utf-8 -*-from PIL import Imagefrom pylab import *from scipy.ndimage import filters# 添加中文字体支持from matplotlib.font_manager import FontPropertiesfont = FontProperties(fname=r&quot;c:\windows\fonts\SimSun.ttc&quot;, size=14)#im = array(Image.open(&apos;board.jpeg&apos;))im = array(Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;).convert(&apos;L&apos;))figure()gray()axis(&apos;off&apos;)subplot(1, 4, 1)axis(&apos;off&apos;)title(u&apos;原图&apos;, fontproperties=font)imshow(im)for bi, blur in enumerate([2, 5, 10]): im2 = zeros(im.shape) im2 = filters.gaussian_filter(im, blur) im2 = np.uint8(im2) imNum=str(blur) subplot(1, 4, 2 + bi) axis(&apos;off&apos;) title(u&apos;标准差为&apos;+imNum, fontproperties=font) imshow(im2)#如果是彩色图像，则分别对三个通道进行模糊#for bi, blur in enumerate([2, 5, 10]):# im2 = zeros(im.shape)# for i in range(3):# im2[:, :, i] = filters.gaussian_filter(im[:, :, i], blur)# im2 = np.uint8(im2)# subplot(1, 4, 2 + bi)# axis(&apos;off&apos;)# imshow(im2)show() 结果截图 图像差分图像强度的改变是一个重要的信息，被广泛用以很多应用中代码 1234567891011121314151617181920212223242526272829303132333435363738394041# -*- coding: utf-8 -*-from PIL import Imagefrom pylab import *from scipy.ndimage import filtersimport numpy# 添加中文字体支持from matplotlib.font_manager import FontPropertiesfont = FontProperties(fname=r&quot;c:\windows\fonts\SimSun.ttc&quot;, size=14)im = array(Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;).convert(&apos;L&apos;))gray()subplot(1, 4, 1)axis(&apos;off&apos;)title(u&apos;(a)原图&apos;, fontproperties=font)imshow(im)# Sobel derivative filtersimx = zeros(im.shape)filters.sobel(im, 1, imx)subplot(1, 4, 2)axis(&apos;off&apos;)title(u&apos;(b)x方向差分&apos;, fontproperties=font)imshow(imx)imy = zeros(im.shape)filters.sobel(im, 0, imy)subplot(1, 4, 3)axis(&apos;off&apos;)title(u&apos;(c)y方向差分&apos;, fontproperties=font)imshow(imy)#mag = numpy.sqrt(imx**2 + imy**2)mag = 255-numpy.sqrt(imx**2 + imy**2)subplot(1, 4, 4)title(u&apos;(d)梯度幅度&apos;, fontproperties=font)axis(&apos;off&apos;)imshow(mag)show() 结果截图 形态学-开、闭操作形态学常用于二值图像，不过它也可以用于灰度图像。二值图像像素只有两种取值，通常是0和1。二值图像通常是由一幅图像进行二值化处理后的产生的，它可以用于用于对物体进行计数，或计算它们的大小。代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344# -*- coding: utf-8 -*-from PIL import Imagefrom numpy import *from scipy.ndimage import measurements, morphologyfrom pylab import *&quot;&quot;&quot; This is the morphology counting objects example in Section 1.4. &quot;&quot;&quot;# 添加中文字体支持from matplotlib.font_manager import FontPropertiesfont = FontProperties(fname=r&quot;c:\windows\fonts\SimSun.ttc&quot;, size=14)# load image and threshold to make sure it is binaryfigure()gray()im = array(Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;).convert(&apos;L&apos;))subplot(221)imshow(im)axis(&apos;off&apos;)title(u&apos;原图&apos;, fontproperties=font)im = (im &lt; 128)labels, nbr_objects = measurements.label(im)print (&quot;Number of objects:&quot;, nbr_objects)subplot(222)imshow(labels)axis(&apos;off&apos;)title(u&apos;标记后的图&apos;, fontproperties=font)# morphology - opening to separate objects betterim_open = morphology.binary_opening(im, ones((9, 5)), iterations=2)subplot(223)imshow(im_open)axis(&apos;off&apos;)title(u&apos;开运算后的图像&apos;, fontproperties=font)labels_open, nbr_objects_open = measurements.label(im_open)print (&quot;Number of objects:&quot;, nbr_objects_open)subplot(224)imshow(labels_open)axis(&apos;off&apos;)title(u&apos;开运算后进行标记后的图像&apos;, fontproperties=font)show() 结果截图 图像降噪图像降噪是一个在尽可能保持图像细节和结构信息时去除噪声的过程代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# -*- coding: utf-8 -*-from PIL import Imagefrom pylab import *from numpy import *from numpy import randomfrom scipy.ndimage import filtersfrom scipy.misc import imsavefrom PCV.tools import rof&quot;&quot;&quot; This is the de-noising example using ROF in Section 1.5. &quot;&quot;&quot;# 添加中文字体支持from matplotlib.font_manager import FontPropertiesfont = FontProperties(fname=r&quot;c:\windows\fonts\SimSun.ttc&quot;, size=14)im = array(Image.open(&apos;C:/Users/LJW/Desktop/dog.jpg&apos;).convert(&apos;L&apos;))U,T = rof.denoise(im,im)G = filters.gaussian_filter(im,10)# save the result#imsave(&apos;synth_original.pdf&apos;,im)#imsave(&apos;synth_rof.pdf&apos;,U)#imsave(&apos;synth_gaussian.pdf&apos;,G)# plotfigure()gray()subplot(1,3,1)imshow(im)#axis(&apos;equal&apos;)axis(&apos;off&apos;)title(u&apos;原噪声图像&apos;, fontproperties=font)subplot(1,3,2)imshow(G)#axis(&apos;equal&apos;)axis(&apos;off&apos;)title(u&apos;高斯模糊后的图像&apos;, fontproperties=font)subplot(1,3,3)imshow(U)#axis(&apos;equal&apos;)axis(&apos;off&apos;)title(u&apos;ROF降噪后的图像&apos;, fontproperties=font)show() 结果截图]]></content>
      <categories>
        <category>计算机视觉</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[粒子群算法的群优算法]]></title>
    <url>%2F2019%2F12%2F03%2F%E7%B2%92%E5%AD%90%E7%BE%A4%E7%AE%97%E6%B3%95%E7%9A%84%E7%BE%A4%E4%BC%98%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[粒子群算法的群优算法介绍 什么是粒子群算法粒子群算法（也称PSO算法）是一种进化算法，模拟生物群体的觅食行为，是一种群体智能算法。PSO是通过当前已知种群寻找到的所有解来决定新的解的寻找方向，也就是新解的生成方式依赖于这些种群历史上寻找的所有解 粒子群算法的算法步骤1.初始化粒子群个体；2.计算每个个体的适应度值（函数值）作为评判好坏的标准；3.找到每个个体自己在所有迭代过程中的最优解Pbest；4.找到所有个体在所有迭代过程中的最优解Zbest；5.根据速度公式更新速度；6.根据位置公式更新位置；7.重复步骤二直至迭代次数结束 粒子群算法的流程图 粒子群算法根据以下公式更新自己的速度和位置 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687pos.m%% 清空环境clcclear%% 参数初始化%粒子群算法中的三个参数c1 = 1.5;%加速因子c2 = 1.5;w=0.8 %惯性权重maxgen=1000; % 进化次s数 sizepop=200; %种群规模Vmax=1; %限制速度围Vmin=-1; popmax=5; %变量取值范围popmin=-5;dim=10; %适应度函数维数func=1; %选择待优化的函数，1为Rastrigin,2为Schaffer,3为GriewankDrawfunc(func);%画出待优化的函数，只画出二维情况作为可视化输出%% 产生初始粒子和速度for i=1:sizepop %随机产生一个种群 pop(i,:)=popmax*rands(1,dim); %初始种群 V(i,:)=Vmax*rands(1,dim); %初始化速度 %计算适应度 fitness(i)=fun(pop(i,:),func); %粒子的适应度end%% 个体极值和群体极值[bestfitness bestindex]=min(fitness);gbest=pop(bestindex,:); %全局最佳pbest=pop; %个体最佳fitnesspbest=fitness; %个体最佳适应度值fitnessgbest=bestfitness; %全局最佳适应度值%% 迭代寻优for i=1:maxgen fprintf(&apos;第%d代，&apos;,i); fprintf(&apos;最优适应度%f\n&apos;,fitnessgbest); for j=1:sizepop %速度更新 V(j,:) = w*V(j,:) + c1*rand*(pbest(j,:) - pop(j,:)) + c2*rand*(gbest - pop(j,:)); %根据个体最优pbest和群体最优gbest计算下一时刻速度 V(j,find(V(j,:)&gt;Vmax))=Vmax; %限制速度不能太大 V(j,find(V(j,:)&lt;Vmin))=Vmin; %种群更新 pop(j,:)=pop(j,:)+0.5*V(j,:); %位置更新 pop(j,find(pop(j,:)&gt;popmax))=popmax;%坐标不能超出范围 pop(j,find(pop(j,:)&lt;popmin))=popmin; if rand&gt;0.98 %加入变异种子，用于跳出局部最优值 pop(j,:)=rands(1,dim); end %更新第j个粒子的适应度值 fitness(j)=fun(pop(j,:),func); end for j=1:sizepop %个体最优更新 if fitness(j) &lt; fitnesspbest(j) pbest(j,:) = pop(j,:); fitnesspbest(j) = fitness(j); end %群体最优更新 if fitness(j) &lt; fitnessgbest gbest = pop(j,:); fitnessgbest = fitness(j); end end yy(i)=fitnessgbest; w=w-0.0005; endfprintf(&apos;w=%d\n&apos;,w);%% 结果分析figure;plot(yy)title(&apos;最优个体适应度&apos;,&apos;fontsize&apos;,12);xlabel(&apos;进化代数&apos;,&apos;fontsize&apos;,12);ylabel(&apos;适应度&apos;,&apos;fontsize&apos;,12); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Drawfunc.mfunction Drawfunc(label)x=-5:0.05:5;%41列的向量if label==1 y = x; [X,Y] = meshgrid(x,y); [row,col] = size(X); for l = 1 :col for h = 1 :row z(h,l) = Rastrigin([X(h,l),Y(h,l)]); end end surf(X,Y,z); shading interp xlabel(&apos;x1-axis&apos;),ylabel(&apos;x2-axis&apos;),zlabel(&apos;f-axis&apos;); title(&apos;mesh&apos;); endif label==2 y = x; [X,Y] = meshgrid(x,y); [row,col] = size(X); for l = 1 :col for h = 1 :row z(h,l) = Schaffer([X(h,l),Y(h,l)]); end end surf(X,Y,z); shading interp xlabel(&apos;x1-axis&apos;),ylabel(&apos;x2-axis&apos;),zlabel(&apos;f-axis&apos;); title(&apos;mesh&apos;); endif label==3 y = x; [X,Y] = meshgrid(x,y); [row,col] = size(X); for l = 1 :col for h = 1 :row z(h,l) = Griewank([X(h,l),Y(h,l)]); end end surf(X,Y,z); shading interp xlabel(&apos;x1-axis&apos;),ylabel(&apos;x2-axis&apos;),zlabel(&apos;f-axis&apos;); title(&apos;mesh&apos;); end 123456789101112fun.mfunction y = fun(x,label)%函数用于计算粒子适应度值%x input 输入粒子 %y output 粒子适应度值 if label==1 y=Rastrigin(x);elseif label==2 y=Schaffer(x);else y= Griewank(x);end 12345678fun.mfunction y = fun(x)%函数用于计算粒子适应度值%x input 输入粒子 %y output 粒子适应度值 y=-20*exp(-0.2*sqrt((x(1)^2+x(2)^2)/2))-exp((cos(2*pi*x(1))+cos(2*pi*x(2)))/2)+20+exp(1);%y=x(1)^2-10*cos(2*pi*x(1))+10+x(2)^2-10*cos(2*pi*x(2))+10; 1234567891011121314151617Griewank.mfunction y=Griewank(x)%Griewan函数%输入x,给出相应的y值,在x=(0,0,…,0)处有全局极小点0.%编制人：%编制日期：[row,col]=size(x);if row&gt;1 error(&apos;输入的参数错误&apos;);endy1=1/4000*sum(x.^2);y2=1;for h=1:col y2=y2*cos(x(h)/sqrt(h));endy=y1-y2+1;%y=-y; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879posMotation.m%% 清空环境clcclear%% 参数初始化%粒子群算法中的两个参数c1 = 1.49445;c2 = 1.49445;maxgen=500; % 进化次数 sizepop=100; %种群规模Vmax=1;Vmin=-1;popmax=5;popmin=-5;%% 产生初始粒子和速度for i=1:sizepop %随机产生一个种群 pop(i,:)=5*rands(1,2); %初始种群 V(i,:)=rands(1,2); %初始化速度 %计算适应度 fitness(i)=fun(pop(i,:)); %染色体的适应度end%% 个体极值和群体极值[bestfitness bestindex]=min(fitness);zbest=pop(bestindex,:); %全局最佳gbest=pop; %个体最佳fitnessgbest=fitness; %个体最佳适应度值fitnesszbest=bestfitness; %全局最佳适应度值%% 迭代寻优for i=1:maxgen for j=1:sizepop %速度更新 V(j,:) = V(j,:) + c1*rand*(gbest(j,:) - pop(j,:)) + c2*rand*(zbest - pop(j,:)); V(j,find(V(j,:)&gt;Vmax))=Vmax; V(j,find(V(j,:)&lt;Vmin))=Vmin; %种群更新 pop(j,:)=pop(j,:)+0.5*V(j,:); pop(j,find(pop(j,:)&gt;popmax))=popmax; pop(j,find(pop(j,:)&lt;popmin))=popmin; if rand&gt;0.98 pop(j,:)=rands(1,2); end %适应度值 fitness(j)=fun(pop(j,:)); end for j=1:sizepop %个体最优更新 if fitness(j) &lt; fitnessgbest(j) gbest(j,:) = pop(j,:); fitnessgbest(j) = fitness(j); end %群体最优更新 if fitness(j) &lt; fitnesszbest zbest = pop(j,:); fitnesszbest = fitness(j); end end yy(i)=fitnesszbest; end%% 结果分析plot(yy)title(&apos;最优个体适应度&apos;,&apos;fontsize&apos;,12);xlabel(&apos;进化代数&apos;,&apos;fontsize&apos;,12);ylabel(&apos;适应度&apos;,&apos;fontsize&apos;,12); 123456789101112Rastrigin.mfunction y = Rastrigin(x)% Rastrigin函数% 输入x,给出相应的y值,在x = ( 0 , 0 ,…, 0 )处有全局极小点0.% 编制人：% 编制日期：[row,col] = size(x);if row &gt; 1 error( &apos; 输入的参数错误 &apos; );endy =sum(x.^2-10*cos(2*pi*x)+10);%y =-y; 123456789101112Schaffer.mfunction y=Schaffer(x)[row,col]=size(x);if row&gt;1 error(&apos;输入的参数错误&apos;);endy1=x(1,1);y2=x(1,2);temp=y1^2+y2^2;y=0.5-(sin(sqrt(temp))^2-0.5)/(1+0.001*temp)^2;y=-y; 实验结果一.Rastrigin优化函数 c1=2 c2=1 w=1 —&gt; 0.1平均最优适应度为2.5884298 c1=1.9 c2=1.1 w=0.9 —&gt; 0.2平均最优适应度为1.624735 c1=1.8 c2=1.2 w=0.9 —&gt; 0.3平均最优适应度为1.7998702 c1=1.7 c2=1.3 w=0.9 —&gt; 0.6平均最优适应度为2.5892194 c1=1.6 c2=1.4 w=0.8 —&gt; 0.7平均最优适应度为4.974795 c1=1.5 c2=1.5 w=0.8 —&gt; 0.3平均最优适应度为1.0615212 结果分析:迭代1000次，权重递减，初始权重与第1000次迭代的权重值相差越大则最优适应度越小，反之最优适应度越大。c1和c2值越接近，最优适应度越小 种群规模=20 应度函数维数=10平均最优适应度为8.3576504 种群规模=500 应度函数维数=10平均最优适应度为0.7959672 种群规模=200 应度函数维数=3平均最优适应度为0 种群规模=200 应度函数维数=60平均最优适应度为24.277043 结果分析:种群规模越小迭代越快，但易陷于局部最优。种群规模越大，迭代越慢，但搜索准确性高。函数维度越小，最优适应度越快收敛于0 二.Schaffer优化函数 c1=2 c2=1 w=1 —&gt; 0.1平均最优适应度为-1 c1=1.9 c2=1.1 w=0.9 —&gt; 0.2平均最优适应度为-1 c1=1.8 c2=1.2 w=0.9 —&gt; 0.3平均最优适应度为-1 c1=1.7 c2=1.3 w=0.9 —&gt; 0.6平均最优适应度为-1 c1=1.6 c2=1.4 w=0.8 —&gt; 0.7平均最优适应度为-1 c1=1.5 c2=1.5 w=0.8 —&gt; 0.3平均最优适应度为-1 种群规模=20 应度函数维数=10平均最优适应度为-1 种群规模=500 应度函数维数=10平均最优适应度为-1 种群规模=200 应度函数维数=3平均最优适应度为-1 种群规模=200 应度函数维数=60平均最优适应度为-1 三.Griewank优化函数 c1=2 c2=1 w=1 —&gt; 0.1平均最优适应度为0 c1=1.9 c2=1.1 w=0.9 —&gt; 0.2平均最优适应度为0 c1=1.8 c2=1.2 w=0.9 —&gt; 0.3平均最优适应度为0 c1=1.7 c2=1.3 w=0.9 —&gt; 0.6平均最优适应度为0 c1=1.6 c2=1.4 w=0.8 —&gt; 0.7平均最优适应度为0 c1=1.5 c2=1.5 w=0.8 —&gt; 0.3平均最优适应度为0 种群规模=20 应度函数维数=10平均最优适应度为0 种群规模=500 应度函数维数=10平均最优适应度为0 种群规模=200 应度函数维数=3平均最优适应度为0 种群规模=200 应度函数维数=60平均最优适应度为0 结果分析:三个函数只有第一个函数最好。第二个函数和第三个函数，无论怎么改变，第二个最优适应度为-1，第三个则为0 实验结论1.种群规模不宜太少，太少易造成实验误差。但也不宜太大，太大迭代速度太慢。2.惯性权重w如果是一个较大的值，有利于全局搜索，若是太小有利于局部搜索，易陷于局部最优。在迭代初期惯性权重值应该选择较大，这样有利于保持全局搜索的能力，迭代后期则应选择较小的惯性权重，有利于局部搜索，这样实验结果更准确。]]></content>
      <categories>
        <category>计算智能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[遗传算法解决TSP问题]]></title>
    <url>%2F2019%2F11%2F19%2F%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%A7%A3%E5%86%B3TSP%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[遗传算法解决TSP问题，研究不同参数组合对算法实验结果影响 遗传算法什么是遗传算法遗传算法（Genetic Algorithm, GA）是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法。其主要特点是直接对结构对象进行操作，不存在求导和函数连续性的限定；具有内在的隐并行性和更好的全局寻优能力；采用概率化的寻优方法，不需要确定的规则就能自动获取和指导优化的搜索空间，自适应地调整搜索方向。遗传算法以一种群体中的所有个体为对象，并利用随机化技术指导对一个被编码的参数空间进行高效搜索。其中，选择、交叉和变异构成了遗传算法的遗传操作；参数编码、初始群体的设定、适应度函数的设计、遗传操作设计、控制参数设定五个要素组成了遗传算法的核心内容。 遗传算法执行过程遗传算法是从代表问题可能潜在的解集的一个种群（population）开始的，而一个种群则由经过基因（gene）编码的一定数目的个体(individual)组成。每个个体实际上是染色体(chromosome)带有特征的实体。染色体作为遗传物质的主要载体，即多个基因的集合，其内部表现（即基因型）是某种基因组合，它决定了个体的形状的外部表现，如黑头发的特征是由染色体中控制这一特征的某种基因组合决定的。因此，在一开始需要实现从表现型到基因型的映射即编码工作。由于仿照基因编码的工作很复杂，我们往往进行简化，如二进制编码。初代种群产生之后，按照适者生存和优胜劣汰的原理，逐代（generation）演化产生出越来越好的近似解，在每一代，根据问题域中个体的适应度（fitness）大小选择（selection）个体，并借助于自然遗传学的遗传算子（genetic operators）进行组合交叉（crossover）和变异（mutation），产生出代表新的解集的种群。这个过程将导致种群像自然进化一样的后生代种群比前代更加适应于环境，末代种群中的最优个体经过解码（decoding），可以作为问题近似最优解。 图解过程 代码实现main.m 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131%mainclear;clc;%%%%%%%%%%%%%%%输入参数%%%%%%%%N=25; %%城市的个数M=100; %%种群的个数ITER=2000; %%迭代次数%C_old=C;m=2; %%适应值归一化淘汰加速指数Pc=0.8; %%交叉概率Pmutation=0.05; %%变异概率%%生成城市的坐标%pos=randn(N,2);load(&apos;cities.mat&apos;, &apos;pos&apos;);%%生成城市之间距离矩阵D=zeros(N,N);for i=1:N for j=i+1:N dis=(pos(i,1)-pos(j,1)).^2+(pos(i,2)-pos(j,2)).^2; D(i,j)=dis^(0.5); D(j,i)=D(i,j); endend%%生成初始群体popm=zeros(M,N);for i=1:M popm(i,:)=randperm(N);%随机排列，比如[2 4 5 6 1 3]end%%随机选择一个种群R=popm(1,:);figure(1);scatter(pos(:,1),pos(:,2),&apos;rx&apos;);%画出所有城市坐标axis([0 600 0 600]);figure(2);plot_route(pos,R); %%画出初始种群对应各城市之间的连线axis([0 600 0 600]);%%初始化种群及其适应函数fitness=zeros(M,1);len=zeros(M,1);for i=1:M%计算每个染色体对应的总长度 len(i,1)=myLength(D,popm(i,:));endmaxlen=max(len);%最大回路minlen=min(len);%最小回路fitness=fit(len,m,maxlen,minlen);rr=find(len==minlen);%找到最小值的下标，赋值为rrR=popm(rr(1,1),:);%提取该染色体，赋值为Rfor i=1:N fprintf(&apos;%d &apos;,R(i));%把R顺序打印出来endfprintf(&apos;\n&apos;);fitness=fitness/sum(fitness);distance_min=zeros(ITER+1,1); %%各次迭代的最小的种群的路径总长nn=M;iter=0;while iter&lt;=ITER fprintf(&apos;迭代第%d次\n&apos;,iter); %%选择操作 p=fitness./sum(fitness); q=cumsum(p);%累加 for i=1:(M-1) len_1(i,1)=myLength(D,popm(i,:)); r=rand; tmp=find(r&lt;=q); popm_sel(i,:)=popm(tmp(1),:); end [fmax,indmax]=max(fitness);%求当代最佳个体 popm_sel(M,:)=popm(indmax,:); %%交叉操作 nnper=randperm(M);% A=popm_sel(nnper(1),:); % B=popm_sel(nnper(2),:); %% for i=1:M*Pc*0.5 A=popm_sel(nnper(i),:); B=popm_sel(nnper(i+1),:); [A,B]=cross(A,B); % popm_sel(nnper(1),:)=A; % popm_sel(nnper(2),:)=B; popm_sel(nnper(i),:)=A; popm_sel(nnper(i+1),:)=B; end %%变异操作 for i=1:M pick=rand; while pick==0 pick=rand; end if pick&lt;=Pmutation popm_sel(i,:)=Mutation(popm_sel(i,:)); end end %%求适应度函数 NN=size(popm_sel,1); len=zeros(NN,1); for i=1:NN len(i,1)=myLength(D,popm_sel(i,:)); end maxlen=max(len); minlen=min(len); distance_min(iter+1,1)=minlen; fitness=fit(len,m,maxlen,minlen); rr=find(len==minlen); fprintf(&apos;minlen=%d\n&apos;,minlen); R=popm_sel(rr(1,1),:); for i=1:N fprintf(&apos;%d &apos;,R(i)); end fprintf(&apos;\n&apos;); popm=[]; popm=popm_sel; iter=iter+1; %pause(1);end%end of whilefigure(3)plot_route(pos,R);axis([0 600 0 600]);figure(4)plot(distance_min); 交叉操作函数cross.m 12345678910111213141516171819function [A,B]=cross(A,B)L=length(A);if L&lt;10 W=L;elseif ((L/10)-floor(L/10))&gt;=rand&amp;&amp;L&gt;10 W=ceil(L/10)+8;else W=floor(L/10)+8;end%%W为需要交叉的位数p=unidrnd(L-W+1);%随机产生一个交叉位置%fprintf(&apos;p=%d &apos;,p);%交叉位置for i=1:W x=find(A==B(1,p+i-1)); y=find(B==A(1,p+i-1)); [A(1,p+i-1),B(1,p+i-1)]=exchange(A(1,p+i-1),B(1,p+i-1)); [A(1,x),B(1,y)]=exchange(A(1,x),B(1,y));endend 对调函数exchange.m 123456function [x,y]=exchange(x,y)temp=x;x=y;y=temp; end 适应度函数fit.mat 123456%适应度函数fit.m，每次迭代都要计算每个染色体在本种群内部的优先级别，类似归一化参数。越大约好！function fitness=fit(len,m,maxlen,minlen)fitness=len;for i=1:length(len) fitness(i,1)=(1-(len(i,1)-minlen)/(maxlen-minlen+0.0001)).^m;end 变异函数Mutation.m 1234567891011121314function a=Mutation(A)index1=0;index2=0;nnper=randperm(size(A,2));index1=nnper(1);index2=nnper(2);%fprintf(&apos;index1=%d &apos;,index1);%fprintf(&apos;index2=%d &apos;,index2);temp=0;temp=A(index1);A(index1)=A(index2);A(index2)=temp;a=A;end 染色体的路程代价函数myLength.m 12345678%染色体的路程代价函数 mylength.mfunction len=myLength(D,p)%p是一个排列[N,NN]=size(D);len=D(p(1,N),p(1,1));for i=1:(N-1) len=len+D(p(1,i),p(1,i+1));endend 连点画图函数plot_route.m 12345678910111213141516function plot_route(a,R)scatter(a(:,1),a(:,2),&apos;rx&apos;);hold on;plot([a(R(1),1),a(R(length(R)),1)],[a(R(1),2),a(R(length(R)),2)]);hold on;for i=2:length(R) x0=a(R(i-1),1); y0=a(R(i-1),2); x1=a(R(i),1); y1=a(R(i),2); xx=[x0,x1]; yy=[y0,y1]; plot(xx,yy); hold on;endend 数据交叉概率0.8变异概率0.05种群个数10025个城市minlen=2.326282e+0350个城市minlen=1.014044e+0475个城市minlen=1.302770e+04 1分析由上图实验结果得知实验中城市数量越少，更早趋于停滞状态 25个城市交叉概率0.5变异概率0.05种群个数50交叉概率0.2变异概率0.05种群个数20交叉概率0.8变异概率0.05种群个数20交叉概率0.2变异概率0.07种群个数100 1234分析：由上图实验结果可知：1.交叉概率越低，最后实验结果中最短路径越大。2.种群个数太大，实验结果中最短路径越大，种群个数太小波动太大，影响最后结果准确性。 结论1.交叉操作中的概率是用于判定两个个体是否进行交叉操作，一般都会比较大。2.变异操作的概率是允许少数个体存在变异情况，以避免限入局部最优解。一般取值低于0.1]]></content>
      <categories>
        <category>计算智能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[蚁群算法求TSP问题]]></title>
    <url>%2F2019%2F11%2F05%2F%E8%9A%81%E7%BE%A4%E7%AE%97%E6%B3%95%E6%B1%82TSP%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[蚁群算法介绍 什么是蚁群算法蚁群算法就是模拟蚂蚁寻找食物的过程，它能够求出从原点出发，经过若干个给定的需求点，最终返回原点的最短路径。这也就是著名的旅行商问题。 蚁群算法原理1.蚂蚁在路径上释放信息素。2.碰到还没走过的路口，就随机挑选一条路走。同时，释放与路径长度有关的信息素。3.信息素浓度与路径长度成反比。后来的蚂蚁再次碰到该路口时，就选择信息素浓度较高路径。4.最优路径上的信息素浓度越来越大。5.最终蚁群找到最优寻食路径。 蚁群算法基本流程 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148%% 旅行商问题(TSP)优化%% 清空环境变量clear allclc%% 导入数据load citys_data.mat%% 计算城市间相互距离fprintf(&apos;Computing Distance Matrix... \n&apos;);n = size(citys,1);D = zeros(n,n);for i = 1:n for j = 1:n if i ~= j D(i,j) = sqrt(sum((citys(i,:) - citys(j,:)).^2)); else D(i,j) = 1e-4; end end end%% 初始化参数fprintf(&apos;Initializing Parameters... \n&apos;);m = 50; % 蚂蚁数量alpha = 1; % 信息素重要程度因子beta = 2; % 启发函数重要程度因子rho = 0.7; % 信息素挥发因子Q = 1; % 常系数Eta = 1./D; % 启发函数Tau = ones(n,n); % 信息素矩阵Table = zeros(m,n); % 路径记录表iter = 1; % 迭代次数初值iter_max = 150; % 最大迭代次数 Route_best = zeros(iter_max,n); % 各代最佳路径 Length_best = zeros(iter_max,1); % 各代最佳路径的长度 Length_ave = zeros(iter_max,1); % 各代路径的平均长度 %% 迭代寻找最佳路径figure;while iter &lt;= iter_max fprintf(&apos;迭代第%d次\n&apos;,iter); % 随机产生各个蚂蚁的起点城市 start = zeros(m,1); for i = 1:m temp = randperm(n); start(i) = temp(1); end Table(:,1) = start; % 构建解空间 citys_index = 1:n; % 逐个蚂蚁路径选择 for i = 1:m % 逐个城市路径选择 for j = 2:n tabu = Table(i,1:(j - 1)); % 已访问的城市集合(禁忌表) allow_index = ~ismember(citys_index,tabu); allow = citys_index(allow_index); % 待访问的城市集合 P = allow; % 计算城市间转移概率 for k = 1:length(allow) P(k) = Tau(tabu(end),allow(k))^alpha * Eta(tabu(end),allow(k))^beta; end P = P/sum(P); % 轮盘赌法选择下一个访问城市 Pc = cumsum(P); target_index = find(Pc &gt;= rand); target = allow(target_index(1)); Table(i,j) = target; end end % 计算各个蚂蚁的路径距离 Length = zeros(m,1); for i = 1:m Route = Table(i,:); for j = 1:(n - 1) Length(i) = Length(i) + D(Route(j),Route(j + 1)); end Length(i) = Length(i) + D(Route(n),Route(1)); end % 计算最短路径距离及平均距离 if iter == 1 [min_Length,min_index] = min(Length); Length_best(iter) = min_Length; Length_ave(iter) = mean(Length); Route_best(iter,:) = Table(min_index,:); else [min_Length,min_index] = min(Length); Length_best(iter) = min(Length_best(iter - 1),min_Length); Length_ave(iter) = mean(Length); if Length_best(iter) == min_Length Route_best(iter,:) = Table(min_index,:); else Route_best(iter,:) = Route_best((iter-1),:); end end % 更新信息素 Delta_Tau = zeros(n,n); % 逐个蚂蚁计算 for i = 1:m % 逐个城市计算 for j = 1:(n - 1) Delta_Tau(Table(i,j),Table(i,j+1)) = Delta_Tau(Table(i,j),Table(i,j+1)) + Q/Length(i); end Delta_Tau(Table(i,n),Table(i,1)) = Delta_Tau(Table(i,n),Table(i,1)) + Q/Length(i); end Tau = (1-rho) * Tau + Delta_Tau; % 迭代次数加1，清空路径记录表 % figure; %最佳路径的迭代变化过程 [Shortest_Length,index] = min(Length_best(1:iter)); Shortest_Route = Route_best(index,:); plot([citys(Shortest_Route,1);citys(Shortest_Route(1),1)],... [citys(Shortest_Route,2);citys(Shortest_Route(1),2)],&apos;o-&apos;); pause(0.3); iter = iter + 1; Table = zeros(m,n); % endend%% 结果显示[Shortest_Length,index] = min(Length_best);Shortest_Route = Route_best(index,:);disp([&apos;最短距离:&apos; num2str(Shortest_Length)]);disp([&apos;最短路径:&apos; num2str([Shortest_Route Shortest_Route(1)])]);%% 绘图figure(1)plot([citys(Shortest_Route,1);citys(Shortest_Route(1),1)],... [citys(Shortest_Route,2);citys(Shortest_Route(1),2)],&apos;o-&apos;);grid onfor i = 1:size(citys,1) text(citys(i,1),citys(i,2),[&apos; &apos; num2str(i)]);endtext(citys(Shortest_Route(1),1),citys(Shortest_Route(1),2),&apos; 起点&apos;);text(citys(Shortest_Route(end),1),citys(Shortest_Route(end),2),&apos; 终点&apos;);xlabel(&apos;城市位置横坐标&apos;)ylabel(&apos;城市位置纵坐标&apos;)title([&apos;蚁群算法优化路径(最短距离:&apos; num2str(Shortest_Length) &apos;)&apos;])figure(2)plot(1:iter_max,Length_best,&apos;b&apos;,1:iter_max,Length_ave,&apos;r:&apos;)legend(&apos;最短距离&apos;,&apos;平均距离&apos;)xlabel(&apos;迭代次数&apos;)ylabel(&apos;距离&apos;)title(&apos;各代最短距离与平均距离对比&apos;) 实验结果对比1.alpha = 1;beta = 5;rho = 0.5;2.alpha = 10;beta = 10;rho = 0.5;3.alpha = 1;beta = 3;rho = 0.7;4.alpha = 2;beta = 10;rho = 0.5; 实验分析1.第一组实验在28次迭代出现停滞现象2.第二组实验在10次迭代出现停滞现象3.第三组实验在20次迭代出现停滞现象4.第四组实验在30次迭代出现停滞现象可见alpha和beta过大会造成开始时算法收敛速度较快，在随后寻优过程中，迭代一定次数后，容易出现停滞现象。本次实验中，第三组是最优解。 实验总结1.信息素因素alpha反映蚂蚁在运动过程中所积累的信息量在知道蚁群搜索中的相对重要程度。2.启发函数因子beta，反映了启发式信息在知道蚁群搜索过程中的相对重要程度，其大小反映了蚁群巡游过程中小言行、确定性因素的作用强度。b过大是，蚂蚁在某个局部点上选择局优的可能性大。3.rho过小，在各路径上残留的信息素过多，导致无效路径被继续搜索，影响收敛速率。]]></content>
      <categories>
        <category>计算智能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[模糊聚类]]></title>
    <url>%2F2019%2F10%2F27%2F%E6%A8%A1%E7%B3%8A%E8%81%9A%E7%B1%BB%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[模糊控制]]></title>
    <url>%2F2019%2F10%2F22%2F%E6%A8%A1%E7%B3%8A%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[模糊控制器设计实验 算法例子介绍一个人的最终成绩是靠智商和努力共同形成的。输入变量是智商和勤奋度，输出为一个人的成绩。智商，勤奋度，成绩都有三个模糊标记：高、中等、低 主要代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465%模糊控制器设计a=newfis(&apos;fuzzf&apos;); %创建新的模糊推理系统%输入1f1=1; a=addvar(a,&apos;input&apos;,&apos;智商&apos;,[-3*f1,3*f1]); %添加 e 的模糊语言变量a=addmf(a,&apos;input&apos;,1,&apos;高&apos;,&apos;zmf&apos;,[-3*f1,-1*f1]); %添加 e 的模糊语言变量的隶属度函数（z型）a=addmf(a,&apos;input&apos;,1,&apos;一般&apos;,&apos;trimf&apos;,[-3*f1,-2*f1,0]); %隶属度函数为三角形a=addmf(a,&apos;input&apos;,1,&apos;低&apos;,&apos;trimf&apos;,[-3*f1,-1*f1,1*f1]); %输入2f2=1;a=addvar(a,&apos;input&apos;,&apos;勤奋度&apos;,[-3*f2,3*f2]); %添加 ec 的模糊语言变量a=addmf(a,&apos;input&apos;,2,&apos;高&apos;,&apos;zmf&apos;,[-3*f2,-1*f2]); a=addmf(a,&apos;input&apos;,2,&apos;一般&apos;,&apos;trimf&apos;,[-3*f2,-2*f2,0]);a=addmf(a,&apos;input&apos;,2,&apos;低&apos;,&apos;trimf&apos;,[-3*f2,-1*f2,1*f2]);%输出f3=1.5;a=addvar(a,&apos;output&apos;,&apos;成绩&apos;,[-3*f3,3*f3]); %添加 u 的模糊语言变量a=addmf(a,&apos;output&apos;,1,&apos;高&apos;,&apos;zmf&apos;,[-3*f3,-1*f3]); a=addmf(a,&apos;output&apos;,1,&apos;中等&apos;,&apos;trimf&apos;,[-3*f3,-2*f3,0]);a=addmf(a,&apos;output&apos;,1,&apos;低&apos;,&apos;trimf&apos;,[-3*f3,-1*f3,1*f3]);%规则库rulelist=[1 1 1 1 1; %编辑模糊规则，后俩个数分别是规则权重和AND OR选项 1 2 2 1 1; 1 3 3 1 1; 2 1 1 1 1; 2 2 2 1 1; 2 3 3 1 1; 3 1 1 1 1; 3 2 2 1 1; 3 3 3 1 1;]; a=addrule(a,rulelist); %添加模糊规则函数showrule(a) %显示模糊规则函数a1=setfis(a,&apos;DefuzzMethod&apos;,&apos;centroid&apos;); %设置解模糊方法writefis(a1,&apos;fuzzf&apos;); %保存模糊系统a2=readfis(&apos;fuzzf&apos;); %从磁盘读出保存的模糊系统disp(&apos;fuzzy Controller table:e=[-3,+3],ec=[-3,+3]&apos;);%显示矩阵和数组内容%推理Ulist=zeros(3,3); %全零矩阵for i=1:7 for j=1:3 e(i)=-4+i; ec(j)=-4+j; Ulist(i,j)=evalfis([e(i),ec(j)],a2); %完成模糊推理计算 end end% Ulist=ceil(Ulist) %朝正无穷方向取整 Ulist %朝正无穷方向取整 %画出模糊系统figure(1); plotfis(a2); figure(2);plotmf(a,&apos;input&apos;,1);figure(3);plotmf(a,&apos;input&apos;,2);figure(4);plotmf(a,&apos;output&apos;,1); 运行结果 结论对一个人的智商和勤奋度共同促进下的成绩情况进行模糊控制两个输入，智商，勤奋度，分别三个模糊标记，共九种模糊规则]]></content>
      <categories>
        <category>计算智能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[BP神经网络]]></title>
    <url>%2F2019%2F09%2F28%2FBP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[前言由于传统的感知器和线性神经网络有自身无法克服的缺陷，它们都不能解决线性不可分问题，因此在实际应用过程中受到了限制。而BP网络却拥有良好的繁泛化能力、容错能力以及非线性映射能力。因此成为应用最为广泛的一种神经网络。 基于BP算法的多层前馈型网络模型的拓扑结构图 BP算法的基本思想学习过程 第一阶段:第一阶段是信号的正向传播过程；输入信息通过输入层、隐层逐层处理并计算每个单元的实际输出值举个例子:比如你有100万钱，分别投资三个公司。W为投资某个公司的钱占所有钱的百分比，V为每个公司的利润率,收益即为Y=100W1V1+100W2V2+100+W3*V3 第二阶段:第二阶段是误差的反向传递过程；若在输入层未能得到期望的输出值，则逐层递归的计算实际输出和期望输出的差值（即误差），以便根据此差值调节权值。这种过程不断迭代，最后使得信号误差达到允许或规定的范围之内举个例子:有一个游戏叫做”数字炸弹”，规则:一般十个人以上玩，主持人出数字，其他人猜。主持人写下在1-100之间随便1个数字，不能让猜得人知道。其他的人就可以开始猜。如：56。每个人开始猜猜数字，如：A说:30 主持人说：30到100 ，B在从30到100中猜数字说：60，主持人在说：30到60，………… Z说：56，游戏结束主持人反馈的信息就是反向传播代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132% BP网络% BP神经网络的构建net=newff([-1 2;0 5],[3,1],&#123;&apos;tansig&apos;,&apos;purelin&apos;&#125;,&apos;traingd&apos;)net.IW&#123;1&#125;net.b&#123;1&#125;p=[1;2];a=sim(net,p)net=init(net);net.IW&#123;1&#125;net.b&#123;1&#125;a=sim(net,p)%net.IW&#123;1&#125;*p+net.b&#123;1&#125;p2=net.IW&#123;1&#125;*p+net.b&#123;1&#125;a2=sign(p2)a3=tansig(a2)a4=purelin(a3)net.b&#123;2&#125;net.b&#123;1&#125;net.IW&#123;1&#125;net.IW&#123;2&#125;0.7616+net.b&#123;2&#125;a-net.b&#123;2&#125;(a-net.b&#123;2&#125;)/ 0.7616help purelinp1=[0;0];a5=sim(net,p1)net.b&#123;2&#125;% BP网络% BP神经网络的构建net=newff([-1 2;0 5],[3,1],&#123;&apos;tansig&apos;,&apos;purelin&apos;&#125;,&apos;traingd&apos;)net.IW&#123;1&#125;net.b&#123;1&#125;%p=[1;];p=[1;2];a=sim(net,p)net=init(net);net.IW&#123;1&#125;net.b&#123;1&#125;a=sim(net,p)net.IW&#123;1&#125;*p+net.b&#123;1&#125;p2=net.IW&#123;1&#125;*p+net.b&#123;1&#125;a2=sign(p2)a3=tansig(a2)a4=purelin(a3)net.b&#123;2&#125;net.b&#123;1&#125;P=[1.2;3;0.5;1.6]W=[0.3 0.6 0.1 0.8]net1=newp([0 2;0 2;0 2;0 2],1,&apos;purelin&apos;);net2=newp([0 2;0 2;0 2;0 2],1,&apos;logsig&apos;);net3=newp([0 2;0 2;0 2;0 2],1,&apos;tansig&apos;);net4=newp([0 2;0 2;0 2;0 2],1,&apos;hardlim&apos;);net1.IW&#123;1&#125;net2.IW&#123;1&#125;net3.IW&#123;1&#125;net4.IW&#123;1&#125;net1.b&#123;1&#125;net2.b&#123;1&#125;net3.b&#123;1&#125;net4.b&#123;1&#125;net1.IW&#123;1&#125;=W;net2.IW&#123;1&#125;=W;net3.IW&#123;1&#125;=W;net4.IW&#123;1&#125;=W;a1=sim(net1,P)a2=sim(net2,P)a3=sim(net3,P)a4=sim(net4,P)init(net1);net1.b&#123;1&#125;help tansig% 训练p=[-0.1 0.5]t=[-0.3 0.4]w_range=-2:0.4:2;b_range=-2:0.4:2;ES=errsurf(p,t,w_range,b_range,&apos;logsig&apos;);%单输入神经元的误差曲面plotes(w_range,b_range,ES)%绘制单输入神经元的误差曲面pause(0.5);hold off;net=newp([-2,2],1,&apos;logsig&apos;);net.trainparam.epochs=100;net.trainparam.goal=0.001;figure(2);[net,tr]=train(net,p,t);title(&apos;动态逼近&apos;)wight=net.iw&#123;1&#125;bias=net.bpause;close;% 练p=[-0.2 0.2 0.3 0.4]t=[-0.9 -0.2 1.2 2.0]h1=figure(1);net=newff([-2,2],[5,1],&#123;&apos;tansig&apos;,&apos;purelin&apos;&#125;,&apos;trainlm&apos;);net.trainparam.epochs=100;net.trainparam.goal=0.0001;net=train(net,p,t);a1=sim(net,p)pause;h2=figure(2);plot(p,t,&apos;*&apos;);title(&apos;样本&apos;)title(&apos;样本&apos;);xlabel(&apos;Input&apos;);ylabel(&apos;Output&apos;);pause;hold on;ptest1=[0.2 0.1]ptest2=[0.2 0.1 0.9]a1=sim(net,ptest1);a2=sim(net,ptest2);net.iw&#123;1&#125;net.iw&#123;2&#125;net.b&#123;1&#125;net.b&#123;2&#125; 结果截图]]></content>
      <categories>
        <category>计算智能</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[github+hexo搭建博客]]></title>
    <url>%2F2019%2F09%2F20%2Fgithub-hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[利用Github+Hexo搭建个人博客 准备工作 申请github账号github官网 下载并安装 Node.js下载与安装教程 下载并安装 Git下载与安装教程 安装Hexo和本地部署博客4.1. 新建文件夹Hexo(以后代码都放这)4.2. 在 Hexo 目录下 鼠标右键选择Git Bash Here4.3. 输入命令npm install -g hexo-cli4.4. 查看是否安装成功，输入hexo -v 安装成功4.5. 输入hexo init回车-&gt;输入npm install之后会生成一些文件夹4.6. 输入hexo s-&gt;打开浏览器输入http://localhost:4000/即可看到本地博客部署 github搭建github博客 登陆自己的github账号 新建一个仓库 ：点击在右上角+-&gt;New repository-&gt;在Repository name 输入仓库名字 xxx.github.io以后仓库名就是你的博客地址。 配置SSH Key ：一般在你的C盘用户目录下-&gt;找到隐藏文件.ssh文件夹-&gt;有私钥id_rsa 公钥id_rsa.pub-&gt;复制公钥(如果没有.ssh文件夹，打开Git Bush输入 ssh-keygen -t rsa -C &quot;你的邮箱地址&quot;)在你的github选择settings进入到 在Git Bush输入ssh -T git@github.com查看是否配置成功 将本地博客部署到github 安装github插件依赖：在Hexo文件目录下打开Git Bash输入npm install hexo-deployer-git --save 修改站点文件(Hexo文件夹下_config.yml) 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:&lt;github账号名称&gt;/&lt;github账号名称&gt;.github.io.git branch: master 输入hexo g &amp;&amp; hexo d-&gt;在浏览器输入http://xxx.github.io即可看到本地博客部署到github上s]]></content>
  </entry>
  <entry>
    <title><![CDATA[K-Means]]></title>
    <url>%2F2019%2F09%2F17%2FK-Means%2F</url>
    <content type="text"><![CDATA[K-means算法介绍 从D中随机取k个元素，作为k个簇的各自的中心。 分别计算剩下的元素到k个簇中心的相异度，将这些元素分别划归到相异度最低的簇。 根据聚类结果，重新计算k个簇各自的中心，计算方法是取簇中所有元素各自维度的算术平均数。 将D中全部元素按照新的中心重新聚类。 重复第4步，直到聚类结果不再变化。 将结果输出。JAVA代码实现分装Point类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package Kmeans;public class Point &#123; private float[] localArray; private int id; private int clusterId; // 标识属于哪个类中心。 private float dist; // 标识和所属类中心的距离。 public Point(int id, float[] localArray) &#123; this.id = id; this.localArray = localArray; &#125; public Point(float[] localArray) &#123; this.id = -1; //表示不属于任意一个类 this.localArray = localArray; &#125; public float[] getlocalArray() &#123; return localArray; &#125; public int getId() &#123; return id; &#125; public void setClusterId(int clusterId) &#123; this.clusterId = clusterId; &#125; public int getClusterid() &#123; return clusterId; &#125; public float getDist() &#123; return dist; &#125; public void setDist(float dist) &#123; this.dist = dist; &#125; @Override public String toString() &#123; String result = "Point_id=" + id + " ["; for (int i = 0; i &lt; localArray.length; i++) &#123; result += localArray[i] + " "; &#125; return result.trim()+"] clusterId: "+clusterId+" dist: "+dist; &#125; @Override public boolean equals(Object obj) &#123; if (obj == null || getClass() != obj.getClass()) return false; Point point = (Point) obj; if (point.localArray.length != localArray.length) return false; for (int i = 0; i &lt; localArray.length; i++) &#123; if (Float.compare(point.localArray[i], localArray[i]) != 0) &#123; return false; &#125; &#125; return true; &#125; @Override public int hashCode() &#123; float x = localArray[0]; float y = localArray[localArray.length - 1]; long temp = x != +0.0d ? Double.doubleToLongBits(x) : 0L; int result = (int) (temp ^ (temp &gt;&gt;&gt; 32)); temp = y != +0.0d ? Double.doubleToLongBits(y) : 0L; result = 31 * result + (int) (temp ^ (temp &gt;&gt;&gt; 32)); return result; &#125;&#125; 封装Cluster123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package Kmeans;import java.util.ArrayList;import java.util.List; public class Cluster &#123; private int id;// 标识 private Point center;// 中心 private List&lt;Point&gt; members = new ArrayList&lt;Point&gt;();// 成员 public Cluster(int id, Point center) &#123; this.id = id; this.center = center; &#125; public Cluster(int id, Point center, List&lt;Point&gt; members) &#123; this.id = id; this.center = center; this.members = members; &#125; public void addPoint(Point newPoint) &#123; if (!members.contains(newPoint))&#123; members.add(newPoint); &#125;else&#123; System.out.println("样本数据点 &#123;"+newPoint.toString()+"&#125; 已经存在！"); &#125; &#125; public int getId() &#123; return id; &#125; public Point getCenter() &#123; return center; &#125; public void setCenter(Point center) &#123; this.center = center; &#125; public List&lt;Point&gt; getMembers() &#123; return members; &#125; @Override public String toString() &#123; String toString = "Cluster \n" + "Cluster_id=" + this.id + ", center:&#123;" + this.center.toString()+"&#125;"; for (Point point : members) &#123; toString+="\n"+point.toString(); &#125; return toString+"\n"; &#125;&#125; 求两个点的欧式距离12345678910111213141516171819202122package Kmeans;public class DistanceCompute &#123; /** * 求欧式距离 */ public double getEuclideanDis(Point p1, Point p2) &#123; double count_dis = 0; float[] p1_local_array = p1.getlocalArray(); float[] p2_local_array = p2.getlocalArray(); if (p1_local_array.length != p2_local_array.length) &#123; throw new IllegalArgumentException("length of array must be equal!"); &#125; for (int i = 0; i &lt; p1_local_array.length; i++) &#123; count_dis += Math.pow(p1_local_array[i] - p2_local_array[i], 2); &#125; return Math.sqrt(count_dis); &#125;&#125; 核心运行类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154package Kmeans;import java.util.ArrayList;import java.util.HashSet;import java.util.List;import java.util.Random;import java.util.Set; public class KMeansRun &#123; private int kNum; //簇的个数 private int iterNum = 10; //迭代次数 private int iterMaxTimes = 100000; //单次迭代最大运行次数 private int iterRunTimes = 0; //单次迭代实际运行次数 private float disDiff = (float) 0.01; //单次迭代终止条件，两次运行中类中心的距离差 private List&lt;float[]&gt; original_data =null; //用于存放，原始数据集 private static List&lt;Point&gt; pointList = null; //用于存放，原始数据集所构建的点集 private DistanceCompute disC = new DistanceCompute(); private int len = 0; //用于记录每个数据点的维度 public KMeansRun(int k, List&lt;float[]&gt; original_data) &#123; this.kNum = k; this.original_data = original_data; this.len = original_data.get(0).length; //检查规范 check(); //初始化点集。 init(); &#125; /** * 检查规范 */ private void check() &#123; if (kNum == 0)&#123; throw new IllegalArgumentException("k must be the number &gt; 0"); &#125; if (original_data == null)&#123; throw new IllegalArgumentException("program can't get real data"); &#125; &#125; /** * 初始化数据集，把数组转化为Point类型。 */ private void init() &#123; pointList = new ArrayList&lt;Point&gt;(); for (int i = 0, j = original_data.size(); i &lt; j; i++)&#123; pointList.add(new Point(i, original_data.get(i))); &#125; &#125; /** * 随机选取中心点，构建成中心类。 */ private Set&lt;Cluster&gt; chooseCenterCluster() &#123; Set&lt;Cluster&gt; clusterSet = new HashSet&lt;Cluster&gt;(); Random random = new Random(); for (int id = 0; id &lt; kNum; ) &#123; Point point = pointList.get(random.nextInt(pointList.size())); // 用于标记是否已经选择过该数据。 boolean flag =true; for (Cluster cluster : clusterSet) &#123; if (cluster.getCenter().equals(point)) &#123; flag = false; &#125; &#125; // 如果随机选取的点没有被选中过，则生成一个cluster if (flag) &#123; Cluster cluster =new Cluster(id, point); clusterSet.add(cluster); id++; &#125; &#125; return clusterSet; &#125; /** * 为每个点分配一个类！ */ public void cluster(Set&lt;Cluster&gt; clusterSet)&#123; // 计算每个点到K个中心的距离，并且为每个点标记类别号 for (Point point : pointList) &#123; float min_dis = Integer.MAX_VALUE; for (Cluster cluster : clusterSet) &#123; float tmp_dis = (float) Math.min(disC.getEuclideanDis(point, cluster.getCenter()), min_dis); if (tmp_dis != min_dis) &#123; min_dis = tmp_dis; point.setClusterId(cluster.getId()); point.setDist(min_dis); &#125; &#125; &#125; // 新清除原来所有的类中成员。把所有的点，分别加入每个类别 for (Cluster cluster : clusterSet) &#123; cluster.getMembers().clear(); for (Point point : pointList) &#123; if (point.getClusterid()==cluster.getId()) &#123; cluster.addPoint(point); &#125; &#125; &#125; &#125; /** * 计算每个类的中心位置！ */ public boolean calculateCenter(Set&lt;Cluster&gt; clusterSet) &#123; boolean ifNeedIter = false; for (Cluster cluster : clusterSet) &#123; List&lt;Point&gt; point_list = cluster.getMembers(); float[] sumAll =new float[len]; // 所有点，对应各个维度进行求和 for (int i = 0; i &lt; len; i++) &#123; for (int j = 0; j &lt; point_list.size(); j++) &#123; sumAll[i] += point_list.get(j).getlocalArray()[i]; &#125; &#125; // 计算平均值 for (int i = 0; i &lt; sumAll.length; i++) &#123; sumAll[i] = (float) sumAll[i]/point_list.size(); &#125; // 计算两个新、旧中心的距离，如果任意一个类中心移动的距离大于dis_diff则继续迭代。 if(disC.getEuclideanDis(cluster.getCenter(), new Point(sumAll)) &gt; disDiff)&#123; ifNeedIter = true; &#125; // 设置新的类中心位置 cluster.setCenter(new Point(sumAll)); &#125; return ifNeedIter; &#125; /** * 运行 k-means */ public Set&lt;Cluster&gt; run() &#123; Set&lt;Cluster&gt; clusterSet= chooseCenterCluster(); boolean ifNeedIter = true; while (ifNeedIter) &#123; cluster(clusterSet); ifNeedIter = calculateCenter(clusterSet); iterRunTimes ++ ; &#125; return clusterSet; &#125; /** * 返回实际运行次数 */ public int getIterTimes() &#123; return iterRunTimes; &#125;&#125; 测试类123456789101112131415161718192021222324252627282930313233package Kmeans;import java.util.ArrayList;import java.util.Set; public class Main &#123; public static void main(String[] args) &#123; ArrayList&lt;float[]&gt; dataSet = new ArrayList&lt;float[]&gt;(); dataSet.add(new float[] &#123; 1, 2, 3 &#125;); dataSet.add(new float[] &#123; 3, 3, 3 &#125;); dataSet.add(new float[] &#123; 3, 4, 4&#125;); dataSet.add(new float[] &#123; 5, 6, 5&#125;); dataSet.add(new float[] &#123; 8, 9, 6&#125;); dataSet.add(new float[] &#123; 4, 5, 4&#125;); dataSet.add(new float[] &#123; 6, 4, 2&#125;); dataSet.add(new float[] &#123; 3, 9, 7&#125;); dataSet.add(new float[] &#123; 5, 9, 8&#125;); dataSet.add(new float[] &#123; 4, 2, 10&#125;); dataSet.add(new float[] &#123; 1, 9, 12&#125;); dataSet.add(new float[] &#123; 7, 8, 112&#125;); dataSet.add(new float[] &#123; 7, 8, 4&#125;); KMeansRun kRun =new KMeansRun(3, dataSet); Set&lt;Cluster&gt; clusterSet = kRun.run(); System.out.println("单次迭代运行次数："+kRun.getIterTimes()); for (Cluster cluster : clusterSet) &#123; System.out.println(cluster); &#125; &#125;&#125; 结果截图]]></content>
      <categories>
        <category>计算智能</category>
      </categories>
  </entry>
</search>
